# Лямбда-исчисление

Построим формальное исчисление анонимных функций — лямбда-исчисление.

Сначала определим синтаксис:

$$\begin{array}{rcll}
{\color{red}expr} & ::= & {\color{red}var} & \text{(имя переменной)} \\
 & | & {\lambda\, \color{red}{var}}\,.\; {\color{red}expr} & \text{(абстракция)} \\
 & | & {\color{red}expr\ expr} & \text{(применение)}
\end{array}$$

Имя переменной может содержать более одного символа. Кроме того, мы различаем строчные буквы от заглавных: $ab$ и $aB$ это два разных имени.

Применение левоассоциативно: $\color{red} f\ v_1\ v_2$ означает $({\color{red} f\ v_1})\ {\color{red}v_2}$. Кроме того, абстракция захватывает всё, что находится справа её.

Синтаксис сам по себе это не более чем описание возможных синтаксических деревьев. Это форма без содержания, набор выражений, которому мы потом придадим смысл.

Перед тем, как определять смысл, введём следующие сокращения:
- ${λ\color{red} v_1\, v_2}.\; \color{red}e$ означает $λ\textcolor{red}{v_1}.\;(λ\textcolor{red}{v_2}.\; \textcolor{red}{e})$.
- $λ{\color{red} v_1\,v_2\,v_3}.\; \textcolor{red}e$ означает $λ\textcolor{red}{v_1}.\;(λ\textcolor{red}{v_2}.\; (λ\textcolor{red}{v_3}.\;\textcolor{red}e))$.
- И так далее

Например, $λ x\, y.\; x$ это то же самое, что и $λx.\; λ y.\; x$.

Эти сокращения не являются частью синтаксиса: $λ x\, y.\; x$ и $λx.\; λ y.\; x$ это одно и то же выражение с одним и тем же синтаксическим деревом.

Иногда люди хотят читать выражения вслух. Вот несколько способов прочесть выражение $λx\,y.\; f\ y\ x$:

- «Лямбда икс игрек, эф от игрек от икс»
- «Лямбда икс игрек, эф от игрек икс»
- «Лямбда икс игрек, эф игрек икс»

Определившись с синтаксисом, перейдём к семантике (смыслу). Здесь основную трудностью представляют переменные.

Предназначение переменных в лямбда-выражении — указывать места для подстановки. Однако, у переменных есть имена, и это порождает проблемы.

Первая проблема это неоднозначность: что должно означать $λx.\; λx.\; x$?

Другая проблема связана с подстановкой: если наивно вычислить $(λf\,z.\; f\ z)\ z$, то результатом будет $λz.\; z\ z$. Но при этом вычисление $(λf\,t.\; f\ t)\ z$, даёт $λt.\; z\ t$ — выражение с совсем другим смыслом.

Чтобы решить проблемы с именами, классифицируем переменные по их ролям в выражении. Для начала, пара определений:

- Вхождение переменной в выражение это переменная в конкретной позиции в выражении
- Вхождение переменной при абстракции (например, $x$ в $λx.\; x$) называется *связывающим*

Кроме связывающих вхождений, бывают ещё связанные и свободные вхождения переменных. Рассмотрим их на примере следующего выражения:

```{figure} /_img/lxy.fyx.svg
```

Красные стрелки соединяют связывающие вхождения с соответствующими им местами для подстановки. Вхождения переменных, на которые указывают красные стрелки, мы называем *связанными*.

Синяя стрелка указывает на вхождение переменной $f$, которая не связана ни с какой абстракцией. Мы называем такие вхождения переменных *свободными*. Интуитивно, свободные переменные соответствуют неким внешним определениям.

Вернёмся к $λx.\; λx.\; x$. Мы можем интерпретировать это выражение двумя способами. Либо связав $x$ с внешней абстракцией:

```{figure} /_img/lxx1.svg
```

Либо связав с внутренней:

```{figure} /_img/lxx2.svg
```

Мы выбираем связывание с внутренней абстракцией по следующим причинам:

1. Именно так и интерпретируется подобное выражение в большинстве языков программирования
2. Такое связывание позволяет переиспользовать имя переменной
3. У выражения $λx.\;x$ уже есть смысл — это тождественная функция. И мы не хотим, чтобы смысл этого выражения менялся в зависимости от окружения

Смысл выражения не должен зависеть от имён связанных переменных: хотя $λx.\;x$ и $λt.\;t$ являются синтаксически различными выражениями, по смыслу это одна и та же тождественная функция.

Этот принцип позволяет решить проблему с вычислением $(λf\,z.\; f\ z)\ z$: перед непосредственно подстановкой, мы переименовываем те связывающие переменные, чьи имена совпадают с именами свободных переменных в подставляемом выражении. Например:

$$(λf\,z.\; f\ z)\ z \xrightarrow{\;*\;} (λf\,v.\; f\ v)\ z \xrightarrow{\;*\;} λv.\; z\ v$$

Какие именно новые имена мы даём переменным — значения не имеет, необходимо лишь чтобы они не совпадали с именами свободных переменных в подставляемом выражении.

Мы очертили смысл лямбда-выражений неформально — теперь же опишем их смысл механически, при этом вводя важные понятия и обозначения.

Сначала разберёмся с вхождениями переменных. Исследовать их мы будем на следующем примере:

$$fold\ z\ (λa\,v.\; add\ a\ v)\ (zipMap\ (λx\,y.\; mul\ x\ y)\ x\ y)$$

Это не синтетический пример — ему соответствует код на F#, вычисляющий скалярное произведение векторов:

```fsharp
Seq.zip x y |> Seq.map (fun (x,y) -> x*y) |> Seq.fold (fun a v -> a+v) 0
```

Начнём с синтаксического дерева нашего выражения. Оно довольно большое:

```
@
┝ @
│ ┝ @
│ │ ┝ fold
│ │ ┕ z
│ ┕ λa
│   ┕ λv
│     ┕ @
│       ┝ @
│       │ ┝ add
│       │ ┕ a
│       ┕ v
┕ @
  ┝ @
  │ ┝ @
  │ │ ┝ zipMap
  │ │ ┕ λx
  │ │   ┕ λy
  │ │     ┕ @
  │ │       ┝ @
  │ │       │ ┝ mul
  │ │       │ ┕ x
  │ │       ┕ y
  │ ┕ x
  ┕ y
```

Символ `@` соответствует применению. Для удобства, мы объединяем связывающую переменную и её абстракцию в один узел дерева.

Синтаксическое дерево можно рассматривать как набор путей от корня к листьям:

```
@  @  @   fold
@  @  @   z
@  @  λa  λv    @       @   add
@  @  λa  λv    @       @   a
@  @  λa  λv    @       v
@  @  @   @     zipMap  λx  λy   @  @  mul
@  @  @   @     zipMap  λx  λy   @  @  x
@  @  @   @     zipMap  λx  λy   @  y
@  @  @   x
@  @  y
```

Чтобы связать переменными друг с другом, пронумеруем их.

Сначала, двигаясь вправо, в каждом отдельном пути нумеруем *связывающие* переменные в порядке их появления:

```
@  @  @   fold
@  @  @   z
@  @  λa⁰ λv¹   @       @   add
@  @  λa⁰ λv¹   @       @   a
@  @  λa⁰ λv¹   @       v
@  @  @   @     zipMap  λx⁰ λy¹  @  @  mul
@  @  @   @     zipMap  λx⁰ λy¹  @  @  x
@  @  @   @     zipMap  λx⁰ λy¹  @  y
@  @  @   x
@  @  y
```

Затем, в каждом пути двигаясь от *связанных* переменных к корню, ищем ближайшую связывающую переменную с тем же именем. Если находим, то помечаем связанную переменную тем же индексом, что и у связывающей переменной:

```
@  @  @   fold
@  @  @   z
@  @  λa⁰ λv¹   @       @   add
@  @  λa⁰ λv¹   @       @   a⁰
@  @  λa⁰ λv¹   @       v¹
@  @  @   @     zipMap  λx⁰ λy¹  @  @  mul
@  @  @   @     zipMap  λx⁰ λy¹  @  @  x⁰
@  @  @   @     zipMap  λx⁰ λy¹  @  y¹
@  @  @   x
@  @  y
```

Собирая выражение обратно, получаем:

$$fold\ z\ (λa^0\,v^1.\; add\ a^0\ v^1)\ (zipMap\ (λx^0\,y^1.\; mul\ x^0\ y^1)\ x\ y)$$

Нумерация переменных решает сразу несколько проблем:

1. Неоднозначности исчезают: например, выражение $λx.\;λx.\;x$ превращается в однозначное выражение $λx^0.\;λx^1.\;x^1$
2. Связанные переменные отличаются от свободных — у последних индекса нет
3. В пределах абстракции, индексы однозначно указывают, какие именно переменные связаны со связывающей переменной

Последнее свойство позволяет и вовсе избавиться от имён связанных переменных:

$$fold\ z\ (λ.\;λ.\; add\ \underline{0}\ \underline{1})\ (zipMap\ (λ.\;λ.\; mul\ \underline{0}\ \underline{1})\ x\ y)$$

Это — локально безымянное представление[^nameless]. Перевод в это представление делает выражения, которые раньше совпадали с точностью до переименования связанных переменных, синтаксически одним и тем же выражением.

Это позволяет ввести синтаксическое равенство с точностью до переименования переменных.

**Определение:** выражения $\color{red} a$ и $\color{red} b$ называются альфа-эквивалентными (пишется ${\color{red} a} \equiv_α {\color{red} b}$), если их локально безымянные формы совпадают.

Примеры:

$$(λx.\;x) \equiv_α (λt.\;t) \qquad (λx\,y.\; f\ y\ x)\equiv_α (λy\,x.\; f\ x\ y)$$

Разобравшись с переменными, переходим непосредственно к самой сути лямбда-исчисления.

**Определение:** $\textcolor{red}e[\textcolor{red}x := \textcolor{red}v]$ это выражение, где каждое свободное вхождение переменной $\color{red}x$ заменено на выражение $\color{red}v$.

Эта операция называется подстановкой. Чтобы избежать случайного захвата переменных, перед заменой переменных на значения, подстановка переименовывает все те связывающие переменные в выражении $\color{red}e$, чьи имена совпадают с именами свободных переменных в $\color{red}v$.

С помощью подстановки, запишем правило вычисления лямбда-выражений.

**Правило вычисления лямбда-выражений (бета-редукция):**

$$(λ\textcolor{red}x.\;\textcolor{red}e)\ \textcolor{red}v \longrightarrow {\textcolor{red}e}[{\textcolor{red}x := {\textcolor{red}v}}]$$

Применение бета-редукции это замена подвыражения, соответствующего левой части правила (редекса[^redex]), на выражение в правой части правила.

Запись ${\color{red}e_1} \longrightarrow {\color{red}e_2}$ означает, что с точностью до переименования переменных, результатом применения бета-редукции к ${\color{red}e_1}$ является выражение ${\color{red}e_2}$. Как и раньше, запись ${\color{red}e_1} \xrightarrow{\;*\;} {\color{red}e_2}$ означает, что ${\color{red}e_1}$ вычисляется в ${\color{red}e_2}$ за конечное число шагов.

Бета-редукция завершает описание лямбда-исчисления. Всё исчисление описывается тройкой слов: функции, вычисляемые подстановкой.

Теперь рассмотрим некоторые свойства лямбда-исчисления.

Правило бета-редукции не указывает, к какому именно редексу оно применяется. Поэтому, одно и то же выражение можно вычислять по разному:

$$\begin{aligned}
\underline{(λx\,y.\; x)\ ((λx.\;x)\ z)} &⟶ λy.\; (\underline{(λx.\;x)\ z}) &⟶ λy.\;z \\
(λx\,y.\; x)\ (\underline{(λx.\;x)\ z}) &⟶ \underline{(λx\,y.\; x)\ z} &⟶ λy.\;z
\end{aligned}$$

Подчёркиванием обозначены соответствующие вычислению редексы.

Несмотря на то, что вычислять выражения можно по разному, любые два результата вычисления можно свести к одному и тому же выражению.

**Теорема (Чёрч — Россер):** пусть $\color{red} e$, $\color{red} a$ и $\color{red} b$ это такие выражения, что ${\color{red} e} \xrightarrow{\;*\;} {\color{red} a}$ и ${\color{red} e} \xrightarrow{\;*\;} {\color{red} b}$. Тогда существует такое выражение $\color{red} w$, что ${\color{red} a} \xrightarrow{\;*\;} {\color{red} w}$ и ${\color{red} b} \xrightarrow{\;*\;} {\color{red} w}$.

Наглядно, утверждение теоремы изображается следующей диаграммой:

```{figure} /_img/church-rosser.svg
```

Теорема Чёрча — Россера это важнейшая теорема лямбда-исчисления. Но доказывать мы её не будем.

Важный момент: существование такого выражения $\color{red} w$, что ${\color{red} a} \xrightarrow{\;*\;} {\color{red} w}$ вовсе не означает, что любая стратегия вычисление приводит $\color{red} a$ к $\color{red} w$. Например:

$$\begin{aligned}
(λx\,y.\; y)\ (\underline{(λx.\;x\ x)\ (λx.\;x\ x)}) &⟶ (λx\,y.\; y)\ (\underline{(λx.\;x\ x)\ (λx.\;x\ x)}) &⟶ \dots \\
\underline{ (λx\,y.\; y)\ ((λx.\;x\ x)\ (λx.\;x\ x))} &⟶ λy.\;y
\end{aligned}$$

Подвыражение $(λx.\;x\ x)\ (λx.\;x\ x)$ вычисляется в само себя, так что выражение целиком можно вычислять неограниченно, так и не достигая $λy.\; y$.

Вычисления производят ради каких-то конечных результатов. Определим, что это значит в контексте лямбда-исчисления.

**Определение:** выражение $\color{red} n$ находится в нормальной форме, если оно не содержит редексов

**Определение:** выражение $\color{red} n$ называется нормальной формой выражения $\color{red} e$, если $\color{red} n$ находится в нормальной форме и ${\color{red} e} \xrightarrow{\;*\;} {\color{red} n}$.

Из теоремы Чёрча — Россера следует, что любые две нормальные формы одного и того же выражения альфа-эквивалентны:

1. Так как ${\color{red} e} \xrightarrow{\;*\;} {\color{red} n_1}$ и ${\color{red} e} \xrightarrow{\;*\;} {\color{red} n_2}$, то существует такое $\color{red}w$, что ${\color{red} n_1} \xrightarrow{\;*\;} {\color{red} w}$ и ${\color{red} n_2} \xrightarrow{\;*\;} {\color{red} w}$
2. Но нормальные формы не содержат редексов, так что могут отличаться от $\color{red}w$ лишь именами переменных

Определившись с тем, что такое результат вычисления, введём обобщение равенства выражений по результату.

**Определение:** выражение $\color{red} a$ называется вычислительно равным выражению $\color{red} b$ (пишется ${\color{red} a} \equiv {\color{red} b}$), если существует такое выражение $\color{red} w$, что ${\color{red} a} \xrightarrow{\;*\;} {\color{red} w}$ и ${\color{red} b} \xrightarrow{\;*\;} {\color{red} w}$.

Если у выражений есть нормальная формы, то вычислительное равенство сводится к равенству их нормальных форм. Однако, вычислительное равенство имеет смысл даже для выражений без нормальной формы.

Вычислительное равенство удовлетворяет свойствам эквивалентности:

1. Рефлексивность: ${\color{red} a} \equiv {\color{red} a}$, для любого выражения $\color{red} a$
2. Симметричность: если ${\color{red} a} \equiv {\color{red} b}$, то и ${\color{red} b} \equiv {\color{red} a}$
3. Транзитивность: если ${\color{red} a} \equiv {\color{red} b}$ и ${\color{red} b} \equiv {\color{red} c}$, то и ${\color{red} a} \equiv {\color{red} с}$

Первые два свойства следуют из определения. Последнее же следует из теоремы Чёрча-Россера, что проще всего изобразить диаграммой:

```{figure} /_img/cr-equiv.svg
```

Мы рассмотрели все необходимые нам понятия и свойства лямбда-исчисления. Теперь же посмотрим на него, как на простейший язык программирования.

С помощью функций можно выражать как данные, так и алгоритмы.

Пусть мы применяем алгоритм к какой-то переменной, у которой может быть всего лишь два значения: например, ответ вида «да» или «нет». В зависимости от значения, алгоритм может вычислить некий результат $a$, если значение переменной равно «нет», или же некий другой результат $b$, если значение переменной равно «да».

Если мы посмотрим на такой алгоритм со стороны, то увидим следующее:

$$alg\ no \equiv a \qquad alg\ yes \equiv b$$

Здесь $alg$ это соответствующая алгоритму функция, $no$ это «нет», а $yes$ это «да».

Мы можем определить функцию с тем же поведением в лямбда-исчислении. Для этого сначала определим $no$ и $yes$ следующим образом:

$$no := λn\,y.\; n \qquad yes := λn\,y.\; y$$

Тогда функцию $alg$ можно определить так:

$$alg := λv.\; v\ a\ b$$

Вместо того, чтобы сравнивать значение с чем-либо и выбирать тот или иной результат, мы применяем $v$ к $a$ и $b$, чтобы функция $v$ сама выбрала нужный результат в зависимости от того, каким именно значением она является.

Аналогичным способом можно закодировать натуральные числа в лямбда-исчислении. Вспомним, что каждое число можно представить через $z$ и $s$:

$$0 := z \qquad 1 := s\ z \qquad 2 := s\ (s\ z)\qquad \dots$$

$z$ это нуль, $s\ n$ это число, следующее за числом $n$.

Алгоритм может использовать натуральное число следующим образом: если оно равно нулю, то он вычисляет какое-то значение $v$. Иначе же, если число равно $s\ n$, алгоритм вычисляет какое-то другое значение, которое вообще говоря может зависить от $n$.

В парадигме «значение само выбирает ветку вычисления» это означает следующие равенства:

$$z\ v\ f \equiv v \qquad (s\ n)\ v\ f \equiv (f\ n)$$

В лямбда-исчислении, мы можем определить соответствующие функции $z$ и $s$ так:

$$\begin{aligned}
z &:= λz\, s.\; z \\
s &:= λn.\; λz\, s.\; s\ n
\end{aligned}$$

Таким же образом можно представить списки, деревья и прочие структуры данных. Такое кодирование данных называется кодированием Скотт[^scott]. Схожая идея в объектно-ориентированном программировании называется шаблоном «посетитель».

Теперь перейдём к алгоритмам.

Рекурсивные определения не являются частью лямбда-исчисления. Однако, в нём можно выразить рекурсию опосредованно. Рассмотрим как это делается на примере сложения чисел.

Сначала, запишем сложение как рекурсивную функцию:

$$add\ n\ k = \begin{cases}
n, &k = 0 \\
s\ (add\ n\ p), & k = p+1
\end{cases}$$

Это несколько иное определение сложения, чем то, что мы видели ранее: вместо того, чтобы примерять $s$ к $n$, мы применяем $s$ к $add\ n\ p$.

Мы ищем такое выражение $add$, что

$$add\ n\ k \equiv k\ n\ (λk.\; s\ (add\ n\ k))$$

Функция $add$ применяется к одному и тому же значению $n$ по обе стороны равенства. Поэтому естественно рассматривать это равенство не как определение $add$, а как определение $add\ n$.

Избавимся от $k$ к левой части, введя абстракцию:

$$add\ n \equiv λk.\; k\ n\ (λk.\; s\ (add\ n\ k))$$

И вынесем $add\ n$ наружу, введя ещё абстракцию:

$$add\ n \equiv \big(λa.\; λk.\; k\ n\ (λk.\; s\ (a\ k))\big)\ \big(add\ n\big)$$

Обозначая $f := λa.\; λk.\; k\ n\ (λk.\; s\ (a\ k))$, получаем:

$$add\ n \equiv f\ \big(add\ n\big)$$

Чтобы найти $add\ n$, решим другую, схожую задачу.

Пусть $f$ это какая-то функция. Найдём функцию $Y$, удовлетворяющую следующему равенству:

$$Y\ f \equiv f\ (Y\ f)$$

Чтобы найти $Y$, вспомним выражение, которое вычисляется в само себя:

$$(λx.\;x\ x)\ (λx.\;x\ x) ⟶ (λx.\;x\ x)\ (λx.\;x\ x)$$

Модифицируем выражение так, чтобы оно применяло $f$ к результату:

$$(λx.\;f\ (x\ x))\ (λx.\;f\ (x\ x)) ⟶ f\ \big((λx.\;f\ (x\ x))\ (λx.\;f\ (x\ x))\big)$$

Отсюда:

$$Y\ f \equiv (λx.\;f\ (x\ x))\ (λx.\;f\ (x\ x))$$

Выражение $Y$ называется комбинатором неподвижной точки.

Вернёмся к определению сложения. Используя комбинатор неподвижной точки и подставляя определение $f$, получаем:

$$add\ n \equiv Y\ \big(λa.\; λk.\; k\ n\ (λk.\; s\ (a\ k))\big)$$

Отсюда, мы можем определить сложение как

$$add := λn.\; Y\ \big(λa\,k.\; k\ n\ (λk.\; s\ (a\ k))\big)$$

Аналогичным образом через комбинатор неподвижной точки выражаются и другие рекурсивные функции.

Рассмотрим вычисление c комбинатором неподвижной точки на примере $add\ 3\ 2$:

$$\begin{aligned}
add\ 3\ 2 &\equiv Y\ (add\ 3)\ 2 \\
  &\equiv (add\ 3)\ (Y\ (add\ 3))\ 2 \\
  &\equiv \big(λa\,k.\; k\ 3\ (λk.\; s\ (a\ k))\big)\ \big(Y\ (add\ 3)\big)\ 2 \\
  &\equiv \big(λk.\; k\ 3\ (λk.\; s\ (Y\ (add\ 3)\ k))\big)\ 2 \\
  &\equiv 2\ 3\ (λk.\; s\ (Y\ (add\ 3)\ k)) \\
  &\equiv s\ (Y\ (add\ 3)\ 1) \\
  &\equiv s\ (s\ (Y\ (add\ 3)\ 0)) \\
  &\equiv 5
\end{aligned}$$

## Упражнения

Несколько необязательных упражнений на программирование в лямбда-исчислении.

1. Для натуральных чисел, определить следующие функции:

    1. Предшествующее число: $pred\ z \equiv z$ и $pred\ (s\ n) \equiv n$
    2. Усечённое вычитание: наибольшее из $n - k$ и нуля
    3. Умножение чисел
    4. Неполное деление. Если делитель равен нулю, результатом может быть любое значение
    5. Сравнение: $le\ n\ k \equiv yes$, если $n ⩽ k$, иначе $le\ n\ k \equiv no$

2. Используя кодирование Скотт, выразить списки

    - Подсказка: список $[a,b,c]$ можно представить как $cons\ a\ (cons\ b\ (cons\ c\ nil))$

3. Для списков, определить следующие функции:

    1. Длину списка
    2. $map\ f$, которая применяет $f$ к каждому элементу списка
    3. Сумма всех натуральных чисел в списке

[^nameless]: Для наглядности мы используем уровни де Брёйна вместо индексов де Брёйна.

[^redex]: Aнгл. redex (*red*ucible *ex*pression)

[^scott]: Оно отличается от кодирования Чёрча: в последнем $(s\ (s\ z))\ v\ f \equiv f\ (f\ v)$, когда же кодирование Скотт даёт $(s\ (s\ z))\ v\ f \equiv f\ (s\ z)$.
