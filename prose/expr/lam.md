# Лямбда-исчисление

Мысль о том, что функция — это тоже выражение, находит своё отражение практически во всех современных языках программирования, и люди уже много лет, не задумываясь, пользуются анонимными функциями в прикладных задачах. Классическим примером является процедура сортировки массива или списка, принимающая алгоритм сравнения элементов в качестве аргумента.

Однако для более системного изучения этого явления без фокусировки на особенностях какой-то конкретной реализации анонимных функций (каковые будут отличаться от языка к языку), потребуется более формальный взгляд на то, какую абстрактную структуру представляют анонимные функции в целом. Именно с этой целью появилось лямбда-исчисление.

Лямбда-исчисление — это анонимные функции, превращённые в формальную систему. 

В рамках нашей статьи мы будем рассматривать выражения очень формально: выражение есть (а) некоторый терминальный символ (объявленное имя переменной, константы, функции), либо (б) лямбда-выражение (абстракция, сигнатура и тело анонимной функции), либо (в) применение некоторого выражения к некоторому другому выражению (вызов функции).
  
$$\begin{array}{rcll}
{\color{red}expr} & ::= & {\color{red}var} & \text{(имя переменной)} \\
 & | & {\lambda \color{red}{var}}. {\color{red}expr} & \text{(абстракция, лямбда-выражение)} \\
 & | & {\color{red}expr \\; expr} & \text{(применение)}
\end{array}$$
  
Имя переменной может содержать более одного символа. Кроме того, мы отличаем строчные буквы от заглавных: $ab$ и $aB$ — это два разных имени.

Применение левоассоциативно: $\color{red} f\ v_1\ v_2$ означает $({\color{red} f\ v_1})\ {\color{red}v_2}$. Кроме того, абстракция захватывает всё, что находится справа её. Для ограничения области захвата следует применять скобки ().

Разумеется, в реальных языках программирования не все выражения, допустимые приведённой выше формальной грамматикой, являются осмысленными (в вызове функции первое выражение должно вычисляться в функцию (анонимную или нет), формальные параметры должны получать значения требуемых типов, и так далее). На этапе анализа синтаксиса нас не будут интересовать вопросы семантики (смысла выражения), но мы будем стараться приводить примеры, как можно менее оторванные от реальности.

Мы будем использовать следующее сокращение:
- ${λ\color{red} v_1\, v_2}.\; \color{red}e$ означает $λ\textcolor{red}{v_1}.\;(λ\textcolor{red}{v_2}.\; \textcolor{red}{e})$.
- $λ{\color{red} v_1\,v_2\,v_3}.\; \textcolor{red}e$ означает $λ\textcolor{red}{v_1}.\;(λ\textcolor{red}{v_2}.\; (λ\textcolor{red}{v_3}.\;\textcolor{red}e))$.
- И так далее

Например, $λ x\, y.\; x$ это то же самое, что и $λx.\; λ y.\; x$.

Предназначение переменных — указывать места для подстановки. Однако, наличие имён у переменных порождает проблемы.

Например, что означает $λx.\; λx.\; x$? 

Мы решим подобные неоднозначности довольно механическим способом. Для начала, пара определений:

- Вхождение переменной в выражение — это переменная в конкретной позиции в выражении.

- Вхождение переменной при абстракции (например, ${\color{red}x}$ в $λ{\color{red}x}.\;{\color{red}e}$) называется *связывающим*.

Для удобства мы считаем связывающие вхождения переменных не листом синтаксического дерева, а частью абстракции.

Каждое синтаксическое дерево можно рассматривать как набор путей от корня к листьям. Например, выражение $λf.\; (λx.\; x)\ (λy.\; f\ w)$ раскладывается на пути следующим образом:

- $λf.\;\bullet ⟶ λx.\;\bullet ⟶ x$
- $λf.\;\bullet ⟶ λy.\;\bullet ⟶ \bullet\ \bullet ⟶ f$
- $λf.\;\bullet ⟶ λy.\;\bullet ⟶ \bullet\ \bullet ⟶ w$

В каждом пути пронумеруем переменные следующим образом:

1. Двигаясь слева направо, нумеруем связывающие переменные в порядке их появления
2. Для переменной в конце пути, ищем ближайшую к ней связывающую переменную. Если находим, то помечаем лист той же цифрой, что и у связывающей переменной

Пронумеровав переменные в примере выше, получаем следующие пути:

- $λf^0.\;\bullet ⟶ λx^1.\;\bullet ⟶ x^1$
- $λf^0.\;\bullet ⟶ λy^1.\;\bullet ⟶ \bullet\ \bullet ⟶ f^0$
- $λf^0.\;\bullet ⟶ λy^1.\;\bullet ⟶ \bullet\ \bullet ⟶ w$

Они соответствуют выражению $λf^0.\; (λx^1.\; x^1)\ (λy^1.\; f^0\ w)$.

Нумерация устраняет неоднозначности, связанные с именами. Например, пронумеровав $λx.\; λx.\; x$, получаем $λx^0.\; λx^1.\; x^1$ — выражение, где переменная явным образом связана со внутренней абстракцией, а не внешней.

Кроме того, теперь мы можем классифицировать вхождения переменных в листах синтаксического дерева:

- Пронумерованные вхождения называются *связанными*
- Вхождения без номеров называются *свободными*

Связанные вхождения указывают места для подстановки значений, когда же свободные переменные можно рассматривать как внешние определения.

Можно заметить, что номера сами по себе однозначно указывают места подстановки. Заменив связанные вхождения на номера и удалив связывающие вхождения, получаем локально безымянное предствление.

Вот несколько выражений в локально безымянном предствлении:

$$\begin{aligned}
&λx.\;x &\qquad &λ.\; \underline 0 \\
&λx.\;λy.\;y & &λ.\; λ.\ \underline 1 \\
&(λx.\;λy.\; y\ x)\ z & &(λ.\;λ.\; \underline 1\ \underline 0)\ z \\
&λf.\; (λx.\; x)\ (λy.\; f\ w) & &λ.\; (λ.\; \underline 1)\ (λ.\; \underline 0\ w)
\end{aligned}$$

Выражения $\color{red}e_1$ и $\color{red}e_2$ называются альфа-эквивалентными (пишется $\textcolor{red}{e_1} \equiv_α \textcolor{red}{e_2}$), если их локально безымянные формы совпадает.

Альфа-эквивалентность выражает то, что смысл выражения не зависит от имён связанных переменных: например, $λx.\;x$ и $λt.\;t$ — это по сути одно и то же выражение.

Далее мы будем считать альфа-эквивалентные выражения одним и тем же выражением.

Мы сказали, что свободную переменную можно рассматривать как внешнее определение. Определим подстановку значения на место свободной переменной.

$\textcolor{red}e[\textcolor{red}x := \textcolor{red}v]$ — это выражение, где каждое свободное вхождение переменной $\textcolor{red}x$ заменено на выражение $\textcolor{red}v$.

Например, результатом $(λx.\; I\ I\ x)[I := λt.\; t]$ будет $λx.\; (λt.\;t)\ (λt.\;t)\ x$.

Однако, есть тонкость:

- $(λx.\; f\ x)[f := z]$ это $λx^0.\; z\ x^0$, где $z$ — свободная переменная
- Но если наивно подставить $f := z$ в $λz. f\ z$, то результатом будет $λz^0.\; z^0\ z^0$, где $z$ оказалась связана

Поэтому, подстановка должна давать новые имена связанным переменным, чьи имена совпадают с именами свободных переменных в подставляемом выражении.

И результатом $(λz.\; f\ z)[f := z]$ будет выражениие, где связанная переменная $z$ имеет другое имя — например, $λt.\; z\ t$.

С помощью подстановки можно сформулировать правило вычисления лямбда-выражений:

$$(λ\textcolor{red}x.\;\textcolor{red}e)\ \textcolor{red}v \longrightarrow {\textcolor{red}e}[{\textcolor{red}x := {\textcolor{red}v}}]$$

Это правило называется бета-редукцией. Применение правила это замена подвыражения (*редекса*), соответствующего левой части правила, выражением в правой части правила.

Мы пишем ${\color{red}e_1} ⟶ {\color{red}e_2}$, если применение бета-редукции к ${\color{red}e_1}$ даёт выражение ${\color{red}e_2}$.

Мы пишем ${\color{red}e_1} \xrightarrow{\\;\*\\;} {\color{red}e_2}$, если применение конечного числа (включая нуль) редукций к выражению ${\color{red}e_1}$ даёт выражение ${\color{red}e_2}$.

Правила вычисления не говорят, какой именно редекс заменяется, поэтому одно и то же выражение можно вычислять по разному:

$$\begin{aligned}
(λx\,y.\; x)\ ((λx.\;x)\ z) &⟶ λy.\; ((λx.\;x)\ z) &⟶ λy.\;z \\
(λx\,y.\; x)\ ((λx.\;x)\ z) &⟶ (λx\,y.\; x)\ z &⟶ λy.\;z
\end{aligned}$$

Несмотря на то, что вычислять можно по разному, всегда есть возможность придти к одному и тому же результату.

**Теорема (Чёрч — Россер):** Пусть ${\color{red}e} \xrightarrow{\\;\*\\;} {\color{red}a}$ и ${\color{red}e} \xrightarrow{\\;\*\\;} {\color{red}b}$. Тогда существует такое выражение $\color{red}c$, что ${\color{red}a} \xrightarrow{\\;\*\\;} {\color{red}с}$ и ${\color{red}b} \xrightarrow{\\;\*\\;} {\color{red}c}$.

Это важнейшая теорема лямбда-исчисления. Но доказывать мы её не будем.

Утверждение теоремы можно изобразить диаграммой.

![](/_img/church-rosser.svg)

Выражение $\color{red}a$ вычислительно равно выражению $\color{red}b$ (пишется ${\color{red}a} \equiv {\color{red}b}$), если существует такое выражение $\color{red}c$, что ${\color{red}a} \xrightarrow{\\;\*\\;} {\color{red}c}$ и ${\color{red}b} \xrightarrow{\\;\*\\;} {\color{red}c}$.

Вычислительное равенство удовлетворяет основным свойствам отношения эквивалентности:

- ${\color{red}e} ≡ {\color{red}e}$ (рефлексивность);
- если ${\color{red}a} \equiv {\color{red}b}$, то ${\color{red}b} \equiv {\color{red}a}$ (симметричность);
- если ${\color{red}a} ≡ {\color{red}b}$ и ${\color{red}b} ≡ {\color{red}c}$, то ${\color{red}a} ≡ {\color{red}c}$ (транзитивность).

Первые два свойства следуют непосредственно из определения. Последнее же следует из теоремы Чёрча — Россера, что проще всего показать диаграммой.

![](/_img/cr-equiv.svg)

Выражение $\color{red}n$ находится в нормальной форме, если к нему невозможно применить правило вычисления.

Говорят, что $\color{red}n$ является нормальной формой выражения $\color{red}e$, если $\color{red}n$ находится в нормальной форме и  ${\color{red}e} \xrightarrow{\\;\*\\;} {\color{red}n}$.

Из теоремы Чёрча — Россера следует, что у выражения может быть только одна нормальная форма. Кроме того, если два выражения имеют одну и ту же нормальную форму, то они вычислительно равны.

Не каждое выражение имеет нормальную форму:

$$\begin{aligned}
(λx.\;x\ x)\ (λx.\;x\ x) &⟶ (λx.\;x\ x)\ (λx.\;x\ x) &⟶ \dots \\
(λx.\;x\ x\ x)\ (λx.\;x\ x\ x) &⟶ (λx.\;x\ x\ x)\ (λx.\;x\ x\ x)\ (λx.\;x\ x\ x) &⟶ \dots
\end{aligned}$$

И даже если у выражения есть нормальная форма, не каждая стратегия вычисления к ней приводит:

$$\begin{aligned}
(λx\,y.\; y)\ ((λx.\;x\ x)\ (λx.\;x\ x)) &⟶ (λx\,y.\; y)\ ((λx.\;x\ x)\ (λx.\;x\ x)) &⟶ \dots \\
(λx\,y.\; y)\ ((λx.\;x\ x)\ (λx.\;x\ x)) &⟶ λy.\;y
\end{aligned}$$

Хотя теорема Чёрча — Россера гарантирует, что всегда есть способ достигнуть нормальной формы, она не заставляет ему следовать.

Ранее, мы определяли функции рекурсивно. По аналогии, мы могли бы ввести рекурсивные определения в лямбда-исчисление:

$$r := λx.\; {\color{red}e}\ r\ x$$

Однако, это не требуется, так как рекурсивные вычисления выразимы в лямбда исчислении без каких либо дополнительных расширений.

Чтобы понять, как — определим $r$ чуть иначе:

$$r := (λf.\;λx.\; {\color{red}e}\ f\ x)\ r$$

Чтобы выразить эту функцию в лямбда-исчислении, посмотрим на определение выше как на вычислительное равенство. Обозначив $f := (λf.\;λx.\; {\color{red}e}\ f\ x)$, будем искать такое $r$, что

$$r \equiv f\ r$$

Обобщаем задачу: вместо того, чтобы искать $r$, предполагаем, что $r \equiv Y\ f$ и ищем такое $Y$, что $Y\ f \equiv f\ (Y\ f)$.

Чтобы найти $Y$, вспомним выражение, что вычисляется в само себя:

$$(λx.\;x\ x)\ (λx.\;x\ x) ⟶ (λx.\;x\ x)\ (λx.\;x\ x)$$

Вставив в него $f$, получаем:

$$(λx.\;f\ (x\ x))\ (λx.\;f\ (x\ x)) ⟶ f\ ((λx.\;f\ x\ x)\ (λx.\;f\ x\ x))$$

Но это и есть выражение вида $r \equiv f\ r$. Следовательно:

$$Y\ f \equiv (λx.\;f\ (x\ x))\ (λx.\;f\ (x\ x))$$

Выражение $Y := λf.\;(λx.\;f\ (x\ x))\ (λx.\;f\ (x\ x))$ называется комбинатором неподвижной точки.
